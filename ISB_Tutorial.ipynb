{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISB_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jobindj/ISB2021/blob/main/ISB_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9abvVlk5Lzw"
      },
      "source": [
        "\n",
        "# **ISB Deep Learning Tutorial**\n",
        "\n",
        "Eni Halilaj\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clDqZ--55bPZ"
      },
      "source": [
        "In this CoLab note, you will experience simple deep neural network algorithm to estimate lower extremities joint angles from IMUs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_BmdYlG5sau"
      },
      "source": [
        "<br><br>\n",
        "## Step 1. Download prerequisite libraries\n",
        "There are dependencies (Python libraries) for running the tutorial.\n",
        "<br>\n",
        "The code below downloads those dependencies using `pip install` and check GPU availability to for the inference of the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4UU3rCUx9na"
      },
      "source": [
        "print('Download prerequisite libraries! \\n\\n')\n",
        "\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "\n",
        "print('\\n\\nCheck GPU is available for the neural network')\n",
        "# Check if CUDA (GPU package) is available in your system\n",
        "import torch; print(f\"\\n\\nIs CUDA available?: {torch.cuda.is_available()}\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdayKVM1Rmq7"
      },
      "source": [
        "If it says **False** for the CUDA availability, go to ``Edit`` - ``Notebook Setting`` and set ``Hardware accelerator`` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA5b9grL6Hla"
      },
      "source": [
        "<br><br>\n",
        "## Step 2. Download pretrained models and test data\n",
        "We provide pretrained neural network models and input IMUs data for estimating lower body joint angles. \n",
        "<br>\n",
        "By using the code cells below, you can download those files from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWoeGWip6MoP"
      },
      "source": [
        "\"\"\"Python implementation of downloading files from Google Drive\n",
        "Reference: https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "\n",
        "# Clear the directory\n",
        "!rm -rf *\n",
        "\n",
        "# Download pretrained models and corresponding Python code\n",
        "print('\\n\\nDownload and uncompress pretrained models!')\n",
        "download_file_from_google_drive('1bJJ_lw9XcaiJB83P5n23A1ojrFRlAqQR', './models.zip')\n",
        "!unzip models.zip\n",
        "\n",
        "# Download testset\n",
        "print('\\n\\nDownload and uncompress testing data!')\n",
        "download_file_from_google_drive('1aGzdVEMFmx2-o3-NCsgTkRoSRzvaKBjo', './data.zip')\n",
        "!unzip data.zip\n",
        "\n",
        "!rm -rf *.zip\n",
        "!rm -rf __*\n",
        "\n",
        "print('\\n\\nDownload completed!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv6d9rkY81Ye"
      },
      "source": [
        "<br><br>\n",
        "## Step 3. Choose your model\n",
        "We provide 2 activities (Walking/Running) and 3 joints (Hip/Knee/Ankle). You can change activity and joint variables below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9iAuqyE9cDW"
      },
      "source": [
        "# Select activity and joint you want to predict\n",
        "print(\"Choose activity among 'Walking' and 'Running'!\")\n",
        "print(\"Choose joint among 'Hip', 'Knee', and 'Ankle'!\")\n",
        "activity = 'Walking'\n",
        "joint = 'Knee'\n",
        "\n",
        "assert activity in ['Walking', 'Running']\n",
        "assert joint in ['Hip', 'Knee', 'Ankle']\n",
        "\n",
        "print('\\n'*2 + '#' * 10 + ' Tutorial Setup ' + '#' * 10)\n",
        "print(f'Activity : {activity}')\n",
        "print(f'Joint    : {joint}')\n",
        "print('#' * 36)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ojVEcy0ErmP"
      },
      "source": [
        "<br><br>\n",
        "## Step 4. Load model\n",
        "To load the pretrained neural network model, we first need to build an initialized model from provided Python codes (it can be found in ``models/pure_conv.py`` and ``models/pure_lstm.py``). Then we load the parameters of pretrained model from the checkpoint files (``model.pt`` files)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivze2eNyEuaA"
      },
      "source": [
        "# Load model keyword arguments\n",
        "import pickle\n",
        "with open(f'models/checkpoints/{activity}/{joint}_model_kwargs.pkl', 'rb') as file:\n",
        "    kwargs = pickle.load(file)\n",
        "\n",
        "print('#' * 10 + ' Model Configuration ' + '#' * 10)\n",
        "print(f'Type of the network : {kwargs[\"model_type\"].replace(\"Custom\", \"\")}')\n",
        "if kwargs[\"model_type\"] == \"CustomLSTM\":\n",
        "  print(f'Bidirectional       : {kwargs[\"bidir\"]}')\n",
        "print(f'Number of layers    : {len(kwargs[\"layers\"])}')\n",
        "print(f'Channels of layers  : {kwargs[\"layers\"]}')\n",
        "print(f'Dropout layers      : {kwargs[\"dropout\"]}')\n",
        "print(f'Input channel       : {kwargs[\"inp_size\"]}')\n",
        "print(f'Output channel      : {kwargs[\"outp_size\"]}')\n",
        "print('#' * 41 + '\\n')\n",
        "\n",
        "\n",
        "# Load model\n",
        "from models.pure_conv import CustomConv1D\n",
        "from models.pure_lstm import CustomLSTM\n",
        "\n",
        "model = globals()[kwargs['model_type']](**kwargs)\n",
        "\n",
        "# Load pretrained model parameters\n",
        "state_dict = torch.load(f'models/checkpoints/{activity}/{joint}_model.pt')\n",
        "model.load_state_dict(state_dict)\n",
        "model.to(device=device)\n",
        "\n",
        "print('\\n\\nPretrained model loaded!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrINJ1e-95l8"
      },
      "source": [
        "<br><br>\n",
        "## Step 5. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhb9Yf9S-ReI"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Segment-Joint dictionary\n",
        "SegJointDict = {'Hip': ['pelvis', 'thigh'], 'Knee': ['thigh', 'shank'], 'Ankle': ['shank', 'foot']}\n",
        "\n",
        "# Load IMU data\n",
        "acc1 = np.load(f'data/{activity}/{SegJointDict[joint][0]}_acc.npy')\n",
        "gyr1 = np.load(f'data/{activity}/{SegJointDict[joint][0]}_gyr.npy')\n",
        "acc2 = np.load(f'data/{activity}/{SegJointDict[joint][1]}_acc.npy')\n",
        "gyr2 = np.load(f'data/{activity}/{SegJointDict[joint][1]}_gyr.npy')\n",
        "\n",
        "print('\\n'*2 + '#'*21 + ' Data Information ' + '#' * 21)\n",
        "print(f'IMUs placement: {SegJointDict[joint][0]} and {SegJointDict[joint][1]}')\n",
        "print('Measurement 1 : linear acceleration (m/s^2)')\n",
        "print('Measurement 2 : angular velocity (rad/s)')\n",
        "print(f'Data length   : {acc1.shape[1]/200} seconds (200 fps)')\n",
        "print('#' * 60)\n",
        "\n",
        "\n",
        "# Visualize IMU data\n",
        "print('\\n\\nPlot IMUs data!\\n')\n",
        "plt.close('all')\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "for i, (acc, gyr) in enumerate(zip([acc1, gyr1], [acc2, gyr2])):\n",
        "  ax_acc = fig.add_subplot(2, 2, i+1)\n",
        "  ax_gyr = fig.add_subplot(2, 2, i+3)\n",
        "  for j, axis in enumerate(['X', 'Y', 'Z']):\n",
        "    ax_acc.plot(acc[0, :, j], label=f'{SegJointDict[joint][i]} Acc {axis}')\n",
        "    ax_gyr.plot(gyr[0, :, j], label=f'{SegJointDict[joint][i]} Gyr {axis}')\n",
        "  ax_acc.legend()\n",
        "  ax_gyr.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD-KUmSVhiqu"
      },
      "source": [
        "<br><br>\n",
        "## Step 6. Prepare input data\n",
        "\n",
        "Provided neural network takes inertial sensor data (accelerometer / gyroscope) from two IMUs attached on the adjacent segments. Each sensor measures has 3-dimensional data (X, Y, Z). We added the magnitude of the data as the 4th dimension. Then we normalized the data using the mean and the standard deviation of each data learned from the training set. The following code implementation shows the preprocessing procedure of input IMUs data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcyT0MWOKkt-"
      },
      "source": [
        "# Add magnitude and concatenate all features\n",
        "print('\\n\\nPreprocess IMUs data for the network input!')\n",
        "print('1. Add magnitude as new feature')\n",
        "inputs = []\n",
        "for data in [acc1, gyr1, acc2, gyr2]:\n",
        "  mag = np.linalg.norm(data, axis=-1, keepdims=True)\n",
        "  _data = np.concatenate((data, mag), axis=-1)\n",
        "  inputs += [_data]\n",
        "inputs = np.concatenate(inputs, axis=-1)\n",
        "\n",
        "print('2. Convert data to PyTorch Tensor')\n",
        "inputs = torch.from_numpy(inputs).to(device=device).float()\n",
        "\n",
        "# Normalize input data\n",
        "print('3. Normalize the data')\n",
        "norm_dict = torch.load(f'models/checkpoints/{activity}/{joint}_norm_dict.pt')['params']\n",
        "inputs = (inputs - norm_dict['x_mean']) / norm_dict['x_std']\n",
        "\n",
        "print('\\nPreprocessing completed!')\n",
        "print(f'Input data shape: {inputs.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JLFZEsfjHr0"
      },
      "source": [
        "<br><br>\n",
        "## Step 7. Predict angle\n",
        "By inputting preprocessed input data into the network (called ``model`` here), it predicts normalized joint angle. Then by un-normalizing the angle, we can obtain final joint angle prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i0KrBf0jJw5"
      },
      "source": [
        "from time import time\n",
        "\n",
        "# Run inference\n",
        "model.eval()\n",
        "t1 = time()\n",
        "pred = model(inputs)\n",
        "t2 = time()\n",
        "\n",
        "# Unnormalize prediction\n",
        "pred = pred * norm_dict['y_std'] + norm_dict['y_mean']\n",
        "pred = pred.detach().cpu().numpy()\n",
        "\n",
        "print('\\n\\nPrediction completed!')\n",
        "print('%.2f seconds taken'%(t2-t1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj4JdUZFjYwX"
      },
      "source": [
        "<br><br>\n",
        "## Step 8. Analize the results\n",
        "Here we provide analysis of joint angle prediction. We calculate root-mean-square-error of predicted joint angle compared against ground-truth angle captured from the marker-based motion capture system. Furthermore, we visualize joint angle curve below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJlYlRkKjbUz"
      },
      "source": [
        "# Load groundtruth\n",
        "label = np.load(f'data/{activity}/{joint}_angle.npy')\n",
        "\n",
        "# Align neutral angle (passive-pseudo calibration)\n",
        "pred = pred - pred.mean(axis=1, keepdims=True) + label.mean(axis=1, keepdims=True)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(np.square(pred - label).mean(axis=1)).mean(axis=0)\n",
        "print('\\n'*2 + '#'*10 + ' Root-Mean-Square-Error ' + '#'*10)\n",
        "print(f'Activity          : {activity}')\n",
        "print(f'Joint             : {joint}')\n",
        "print('RMSE-Flex/Ext     : %.2f deg'%rmse[0])\n",
        "print('RMSE-Add/Abd      : %.2f deg'%rmse[1])\n",
        "print('RMSE-Int/Ext Rot  : %.2f deg'%rmse[2])\n",
        "print('#'*44 + '\\n\\n\\n')\n",
        "\n",
        "\n",
        "# Visualize joint angle curve\n",
        "plt.close('all')\n",
        "fig = plt.figure(figsize=(7, 14))\n",
        "\n",
        "for i, axis in enumerate(['Flex/Ext', 'Add/Abd', 'Int/Ext Rot']):\n",
        "  _ax = fig.add_subplot(3, 1, i+1)\n",
        "  _ax.plot(pred[0, :, i], label='Prediction')\n",
        "  _ax.plot(label[0, :, i], label='Ground-Truth')\n",
        "  _ax.set_ylabel(f'RMSE-{axis} (deg)', fontsize=20)\n",
        "  _ax.legend()\n",
        "_ax.set_xlabel('Frames (FPS:200)', fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}